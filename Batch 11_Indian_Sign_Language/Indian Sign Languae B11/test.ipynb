{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "from PIL import Image, ImageTk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Random Forest model and labels\n",
    "labels = {\n",
    "    \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\", \"5\": \"5\", \"6\": \"6\", \"7\": \"7\", \"8\": \"8\", \"9\": \"9\",\n",
    "    \"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"H\": \"H\", \"I\": \"I\", \n",
    "    \"J\": \"J\", \"K\": \"K\", \"L\": \"L\", \"M\": \"M\", \"N\": \"N\", \"O\": \"O\", \"P\": \"P\", \"Q\": \"Q\", \"R\": \"R\", \n",
    "    \"S\": \"S\", \"T\": \"T\", \"U\": \"U\", \"V\": \"V\", \"W\": \"W\", \"X\": \"X\", \"Y\": \"Y\", \"Z\": \"Z\",\n",
    "    \">\": \"Back Space\", \".\": \"Clear\", \"<\": \"Space\", \"|\": \"\"\n",
    "    \n",
    "}\n",
    "#\"1\": \"Back Space\", \"2\": \"Clear\", \"3\": \"Space\", \"4\": \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./ISL_model.p\", \"rb\") as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = model[\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import mediapipe as mp\n",
    "import pickle\n",
    "from PIL import Image, ImageTk\n",
    "import tkinter as tk\n",
    "from tkinter import Text\n",
    "\n",
    "# Load the Random Forest model and labels\n",
    "labels = {\n",
    "    \"1\": \"1\", \"2\": \"2\", \"3\": \"3\", \"4\": \"4\", \"5\": \"5\", \"6\": \"6\", \"7\": \"7\", \"8\": \"8\", \"9\": \"9\",\n",
    "    \"A\": \"A\", \"B\": \"B\", \"C\": \"C\", \"D\": \"D\", \"E\": \"E\", \"F\": \"F\", \"G\": \"G\", \"H\": \"H\", \"I\": \"I\", \n",
    "    \"J\": \"J\", \"K\": \"K\", \"L\": \"L\", \"M\": \"M\", \"N\": \"N\", \"O\": \"O\", \"P\": \"P\", \"Q\": \"Q\", \"R\": \"R\", \n",
    "    \"S\": \"S\", \"T\": \"T\", \"U\": \"U\", \"V\": \"V\", \"W\": \"W\", \"X\": \"X\", \"Y\": \"Y\", \"Z\": \"Z\",\n",
    "    \">\": \"Back Space\", \".\": \"Clear\", \"<\": \"Space\", \"|\": \"\"\n",
    "}\n",
    "with open(\"./ISL_model.p\", \"rb\") as f:\n",
    "    model = pickle.load(f)\n",
    "\n",
    "rf_model = model[\"model\"]\n",
    "\n",
    "# Initialize Mediapipe components\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "\n",
    "# Configure the Hands model\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,\n",
    "    max_num_hands=2,  # Detect up to two hands\n",
    "    min_detection_confidence=0.9\n",
    ")\n",
    "\n",
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Strings to store the concatenated sentence\n",
    "predicted_text = \"\"\n",
    "same_characters = \"\"\n",
    "final_characters = \"\"\n",
    "count = 0\n",
    "\n",
    "# Flag to check if the application is running\n",
    "app_running = True\n",
    "\n",
    "# Function to update each frame and predict the character\n",
    "def update_frame():\n",
    "    global predicted_text, same_characters, final_characters, count\n",
    "    if not app_running:  # Stop if the application is closed\n",
    "        return\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if ret:\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        processed_image = hands.process(frame_rgb)\n",
    "        hand_landmarks = processed_image.multi_hand_landmarks\n",
    "\n",
    "        if hand_landmarks:\n",
    "            for hand_landmark in hand_landmarks:\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmark, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "\n",
    "                x_coordinates = [landmark.x for landmark in hand_landmark.landmark]\n",
    "                y_coordinates = [landmark.y for landmark in hand_landmark.landmark]\n",
    "                min_x, min_y = min(x_coordinates), min(y_coordinates)\n",
    "                \n",
    "                normalized_landmarks = []\n",
    "                for coordinates in hand_landmark.landmark:\n",
    "                    normalized_landmarks.extend([\n",
    "                        coordinates.x - min_x,\n",
    "                        coordinates.y - min_y\n",
    "                    ])\n",
    "                \n",
    "                sample = np.asarray(normalized_landmarks).reshape(1, -1)\n",
    "                predicted_character = rf_model.predict(sample)[0]\n",
    "\n",
    "                if predicted_character != \"|\":\n",
    "                    predicted_text += predicted_character\n",
    "                    \n",
    "                    # Only check previous character if predicted_text has at least 2 characters\n",
    "                    if len(predicted_text) > 1 and predicted_text[-1] != predicted_text[-2]: \n",
    "                        count = 0\n",
    "                        same_characters = \"\"\n",
    "                    else:\n",
    "                        same_characters += predicted_character\n",
    "                        count += 1\n",
    "\n",
    "                    if count == 30: \n",
    "                        if predicted_character == \">\":\n",
    "                            if final_characters:\n",
    "                                final_characters = list(final_characters)\n",
    "                                final_characters.pop()\n",
    "                                final_characters = \"\".join(final_characters)\n",
    "                                text_area.delete(\"1.0\", 'end')\n",
    "                                text_area.insert(\"1.0\", final_characters)\n",
    "\n",
    "                        elif predicted_character == \".\":\n",
    "                            final_characters = \"\"\n",
    "                            text_area.delete(\"1.0\", 'end')\n",
    "\n",
    "                        elif predicted_character == \"<\":\n",
    "                            final_characters += \" \"\n",
    "                            text_area.delete(\"1.0\", 'end')\n",
    "                            text_area.insert(\"1.0\", final_characters)\n",
    "\n",
    "                        else:\n",
    "                            final_characters += str(list(set(same_characters))[0])\n",
    "                            text_area.delete(\"1.0\", 'end')\n",
    "                            text_area.insert(\"1.0\", final_characters)\n",
    "\n",
    "                        count = 0\n",
    "                        same_characters = \"\"\n",
    "\n",
    "                    text_position = (20, 20)\n",
    "                    background_color = (0, 150, 250)\n",
    "                    text_color = (0, 0, 0)\n",
    "                    font_scale = 1\n",
    "                    thickness = 2\n",
    "\n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(predicted_character, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "                    background_top_left = text_position\n",
    "                    background_bottom_right = (text_position[0] + text_width + 180, text_position[1] + text_height + 10)\n",
    "                    cv2.rectangle(frame, background_top_left, background_bottom_right, background_color, -1)\n",
    "\n",
    "                    cv2.putText(\n",
    "                        img=frame,\n",
    "                        text=labels[predicted_character],\n",
    "                        org=(text_position[0] + 5, text_position[1] + text_height),\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=font_scale,\n",
    "                        color=text_color,\n",
    "                        thickness=thickness,\n",
    "                        lineType=cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        video_label.imgtk = imgtk\n",
    "        video_label.configure(image=imgtk)\n",
    "\n",
    "    video_label.after(10, update_frame)\n",
    "\n",
    "# Function to handle closing the Tkinter window\n",
    "def on_closing():\n",
    "    global app_running\n",
    "    app_running = False  # Stop the update loop\n",
    "    cap.release()\n",
    "    root.destroy()\n",
    "\n",
    "# GUI setup using Tkinter\n",
    "root = tk.Tk()\n",
    "root.title(\"ISL Translator\")\n",
    "root.geometry(\"800x600\")\n",
    "root.protocol(\"WM_DELETE_WINDOW\", on_closing)\n",
    "\n",
    "# Video display label\n",
    "video_label = tk.Label(root)\n",
    "video_label.pack()\n",
    "\n",
    "# Text area for displaying translated text\n",
    "text_area = Text(root, height=5, width=50, font=(\"Helvetica\", 16))\n",
    "text_area.pack()\n",
    "\n",
    "# Start video capture\n",
    "update_frame()\n",
    "\n",
    "# Run the Tkinter main loop\n",
    "root.mainloop()\n",
    "\n",
    "# Release resources after closing the GUI\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Editing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Mediapipe components\n",
    "mp_hands = mp.solutions.hands  # Hand tracking solution\n",
    "mp_drawing = mp.solutions.drawing_utils  # Drawing utility\n",
    "mp_drawing_styles = mp.solutions.drawing_styles  # Pre-defined drawing styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure the Hands model\n",
    "hands = mp_hands.Hands(\n",
    "    static_image_mode=False,  # Use dynamic mode for video streams\n",
    "    max_num_hands=2,  # Track at most one hand\n",
    "    min_detection_confidence=0.9  # Set a high detection confidence threshold\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture\n",
    "cap = cv2.VideoCapture(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Strings to store the concatenated sentence\n",
    "predicted_text = \" \"\n",
    "same_characters = \"\"\n",
    "final_characters = \"\"\n",
    "count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to update each frame and predict the character\n",
    "def update_frame(video_label, text_area):\n",
    "    global predicted_text, same_characters, final_characters, count\n",
    "    ret, frame = cap.read()  # Capture frame-by-frame\n",
    "    if ret:\n",
    "        # Process the frame to display hand landmarks and predict the character\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        processed_image = hands.process(frame_rgb)\n",
    "        hand_landmarks = processed_image.multi_hand_landmarks\n",
    "        height, width, _ = frame.shape\n",
    "\n",
    "        if hand_landmarks:\n",
    "            for hand_landmark in hand_landmarks:\n",
    "                # Draw landmarks on the frame\n",
    "                mp_drawing.draw_landmarks(\n",
    "                    frame, hand_landmark, mp_hands.HAND_CONNECTIONS,\n",
    "                    mp_drawing_styles.get_default_hand_landmarks_style(),\n",
    "                    mp_drawing_styles.get_default_hand_connections_style()\n",
    "                )\n",
    "\n",
    "                # Collect landmark coordinates for prediction\n",
    "                x_coordinates = [landmark.x for landmark in hand_landmark.landmark]\n",
    "                y_coordinates = [landmark.y for landmark in hand_landmark.landmark]\n",
    "                min_x, min_y = min(x_coordinates), min(y_coordinates)\n",
    "                \n",
    "                normalized_landmarks = []\n",
    "                for coordinates in hand_landmark.landmark:\n",
    "                    normalized_landmarks.extend([\n",
    "                        coordinates.x - min_x,\n",
    "                        coordinates.y - min_y\n",
    "                    ])\n",
    "                \n",
    "                # Predict the character using the model\n",
    "                sample = np.asarray(normalized_landmarks).reshape(1, -1)\n",
    "                predicted_character = rf_model.predict(sample)[0]\n",
    "\n",
    "                if predicted_character != \"|\":\n",
    "                    predicted_text += predicted_character\n",
    "                    \n",
    "                    # Append the predicted character to the sentence\n",
    "                    if predicted_text[-1] != predicted_text[-2]: \n",
    "                        count = 0\n",
    "                        same_characters = \"\"\n",
    "                    else:\n",
    "                        same_characters += predicted_character\n",
    "                        count += 1\n",
    "\n",
    "                    # Display the concatenated sentence in the text area\n",
    "                    if count == 30: \n",
    "\n",
    "                        if predicted_character == \">\":\n",
    "                            if final_characters:\n",
    "                                final_characters = list(final_characters)\n",
    "                                final_characters.pop()\n",
    "                                final_characters = \"\".join(final_characters)\n",
    "                                text_area.delete(\"1.0\", 'end')\n",
    "                                text_area.insert(\"1.0\", final_characters)\n",
    "\n",
    "                        elif predicted_character == \".\":\n",
    "                            final_characters = \"\"\n",
    "                            text_area.delete(\"1.0\", 'end')\n",
    "\n",
    "                        elif predicted_character == \"<\":\n",
    "                            final_characters += \" \"\n",
    "                            text_area.delete(\"1.0\", 'end')\n",
    "                            text_area.insert(\"1.0\", final_characters)\n",
    "\n",
    "                        else:\n",
    "                            final_characters += str(list(set(same_characters))[0])\n",
    "                            text_area.delete(\"1.0\", 'end')\n",
    "                            text_area.insert(\"1.0\", final_characters)\n",
    "\n",
    "                        count = 0\n",
    "                        same_characters = \"\"\n",
    "\n",
    "                    # Coordinates and colors\n",
    "                    text_position = (20, 20)  # Top-left corner of the text background\n",
    "                    background_color = (0, 150, 250)  # Background color (orange)\n",
    "                    text_color = (0, 0, 0)  # Text color (black)\n",
    "                    font_scale = 1\n",
    "                    thickness = 2\n",
    "\n",
    "                    # Calculate the width and height of the text box\n",
    "                    (text_width, text_height), baseline = cv2.getTextSize(predicted_character, cv2.FONT_HERSHEY_SIMPLEX, font_scale, thickness)\n",
    "\n",
    "                    # Calculate bottom-right corner for the background rectangle based on text size\n",
    "                    background_top_left = text_position\n",
    "                    background_bottom_right = (text_position[0] + text_width + 180, text_position[1] + text_height + 10)\n",
    "\n",
    "                    # Draw the filled rectangle as the background for text\n",
    "                    cv2.rectangle(frame, background_top_left, background_bottom_right, background_color, -1)\n",
    "\n",
    "                    # Draw the text on top of the rectangle\n",
    "                    cv2.putText(\n",
    "                        img=frame,\n",
    "                        text=labels[predicted_character],\n",
    "                        org=(text_position[0] + 5, text_position[1] + text_height),  # Adjust for padding within rectangle\n",
    "                        fontFace=cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                        fontScale=font_scale,\n",
    "                        color=text_color,\n",
    "                        thickness=thickness,\n",
    "                        lineType=cv2.LINE_AA\n",
    "                    )\n",
    "\n",
    "        # Convert the frame to ImageTk format and update the label\n",
    "        img = Image.fromarray(cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))\n",
    "        imgtk = ImageTk.PhotoImage(image=img)\n",
    "        video_label.imgtk = imgtk  # Keep a reference to avoid garbage collection\n",
    "        video_label.configure(image=imgtk)\n",
    "\n",
    "    video_label.after(10, lambda: update_frame(video_label, text_area))  # Repeat every 10 ms\n",
    "\n",
    "# Function to release the video capture\n",
    "def release_video():\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
